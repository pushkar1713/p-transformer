{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.0+cu128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "    SOURCE: --f=/teamspace/studios/this_studio/.local/share/jupyter/runtime/kernel-v33988662bc5523f96b23dbe69e8f181b1147f6d9e.json\n",
      " PREDICTED: — Sì ,        e  e      .  "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from config import get_config, latest_weights_file_path\n",
    "from train import get_model, get_ds, run_validation\n",
    "from translate import translate\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length of source sentence: 309\n",
      "Max length of target sentence: 274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "config = get_config()\n",
    "train_dataloader, val_dataloader, tokenizer_src, tokenizer_tgt = get_ds(config)\n",
    "model = get_model(config, tokenizer_src.get_vocab_size(), tokenizer_tgt.get_vocab_size()).to(device)\n",
    "\n",
    "# Load the pretrained weights\n",
    "model_filename = latest_weights_file_path(config)\n",
    "state = torch.load(model_filename)\n",
    "model.load_state_dict(state['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Crossing the yard past the heap of snow by the lilac bush, he reached the shed.\n",
      "    TARGET: Attraversando il cortile, vicino al mucchio di neve che era accanto alle serenelle, Levin raggiunse la stalla.\n",
      " PREDICTED: Il lustrascarpe dell ’ albergo di neve dal tetto , si era avvicinato alla scala , si avvicinava alla tavola .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: How long he might have lived afterwards I know not, though I know they have a notion in the Brazils that they live a hundred years.\n",
      "    TARGET: Quanto sia vissuto da poi non lo so, benchè io sappia che nel Brasile la vita dei pappagalli dura un centinaio d’anni.\n",
      " PREDICTED: Come si potrebbe immaginarsi quanto io non so , benchè io so che sia in una fortuna che ho ricevuto una città .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: It was not he, but she, who became abashed.\n",
      "    TARGET: Non lui, ma lei si turbò.\n",
      " PREDICTED: Non era , ma lei , ma lei .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Dolly, just a word!' he said, following her.\n",
      "    TARGET: — Dolly, ancora una parola — disse seguendola.\n",
      " PREDICTED: — Dolly , Dolly , Dolly , alzandosi . — disse , alzandosi .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'Yes – that he was in love with that girl who died...'\n",
      "    TARGET: — Sì, che era innamorato di quella ragazza che è morta....\n",
      " PREDICTED: — Sì , è innamorato di quella ragazza che era morta ....\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: But what d'you think, Constantine, is it not time?' he added.\n",
      "    TARGET: E che, non è ora Kostja? — aggiunse.\n",
      " PREDICTED: Ma che vuoi , Kostja , Konstantin Dmitric ? — aggiunse .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: Nowadays oats are forty-five kopeks at the inns.\n",
      "    TARGET: Al giorno d’oggi l’avena, dai portieri, sta a quarantacinque copeche.\n",
      " PREDICTED: Al lavoro è il lavoro di avena , i portieri , il campo .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: 'There is a way out of every position.\n",
      "    TARGET: — Da qualsiasi situazione c’è una via d’uscita.\n",
      " PREDICTED: — Ecco , ecco , ecco la situazione .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: But in spite of his affection and respect for Koznyshev, Constantine did not feel at ease with his step-brother in the country.\n",
      "    TARGET: Ma, pur avendo stima ed affetto per Sergej Ivanovic, in campagna Konstantin Levin non si trovava a suo agio con lui.\n",
      " PREDICTED: Ma , pur senza volere , per Sergej Ivanovic , Konstantin Levin non si era occupato col fratello , non si era in campagna .\n",
      "--------------------------------------------------------------------------------\n",
      "    SOURCE: He rose and went toward the door.\n",
      "    TARGET: Si alzò e si diresse verso la porta.\n",
      " PREDICTED: Egli si alzò e si diresse verso la porta .\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# writer = SummaryWriter(\"inference test\")\n",
    "run_validation(model, val_dataloader,tokenizer_src, tokenizer_tgt, config['seq_len'], device, lambda msg: print(msg), 0, None, num_examples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SOURCE: why are we doing this?\n",
      " PREDICTED: Perché non ci vediamo ?  "
     ]
    }
   ],
   "source": [
    "t = translate(\"why are we doing this?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = translate(34)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "this_studio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
